{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87976e75-c792-473d-939e-f79b97853e25",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Bienvenue dans ce notebook où nous allons explorer un aspect fascinant de l'apprentissage profond - la génération automatique de texte. L'objectif de ce projet est d'entraîner un modèle de réseau de neurones à générer des textes qui ressemblent à ceux de William Shakespeare, l'un des écrivains les plus emblématiques de l'histoire.\n",
    "\n",
    "Pour ce faire, nous utiliserons une architecture de réseau neuronal appelée Long Short-Term Memory (LSTM). Les LSTM sont une sous-catégorie spéciale de réseaux de neurones récurrents (RNN) qui sont particulièrement efficaces pour apprendre de longues séquences de données, comme des phrases ou des paragraphes, et donc très appropriées pour des tâches comme la génération de texte.\n",
    "\n",
    "Pour entraîner notre modèle, nous utiliserons un corpus de textes de Shakespeare. Ce corpus servira de base d'apprentissage à notre LSTM pour lui permettre d'apprendre le \"style\" d'écriture de Shakespeare. Une fois entraîné, le modèle sera capable de générer de nouvelles phrases en s'inspirant de ce qu'il a appris de ce corpus.\n",
    "\n",
    "Il est important de noter que le texte généré par notre modèle ne sera pas un véritable Shakespeare, il n'aura pas le même niveau de profondeur ou de signification. Cependant, il devrait présenter des similitudes stylistiques, comme des tournures de phrase similaires, le vocabulaire et la structure grammaticale que l'on trouve couramment dans les œuvres de Shakespeare.\n",
    "\n",
    "Dans ce notebook, nous allons :\n",
    "\n",
    "- Préparer et prétraiter notre corpus de textes.\n",
    "- Construire notre modèle LSTM à l'aide de Keras, une bibliothèque Python populaire pour l'apprentissage profond.\n",
    "- Entraîner ce modèle sur notre corpus.\n",
    "- Générer de nouveaux textes à partir du modèle entraîné.\n",
    "\n",
    "C'est un voyage passionnant à la croisée de la littérature et de l'intelligence artificielle. Alors, allons-y et voyons ce que notre machine peut créer !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51233822-1709-4854-a181-b40ac0e30afa",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af52b49b-2aae-47d0-8f01-28e6140d49f0",
   "metadata": {},
   "source": [
    "# Préparation et prétraitement des données\n",
    "\n",
    "Dans ce bloc de code, nous commençons par importer les bibliothèques nécessaires pour notre projet. Cela comprend `random`, `numpy` et plusieurs sous-bibliothèques de `tensorflow` dont nous avons besoin pour construire et entraîner notre modèle LSTM.\n",
    "\n",
    "Ensuite, nous utilisons la fonction `get_file` de `tensorflow.keras.utils` pour télécharger le fichier de texte 'shakespeare.txt' qui contient notre corpus. Ce fichier est lu, décodé en 'utf-8', converti en minuscules pour normaliser le texte et nous remplaçons les retours à la ligne par des espaces pour faciliter le traitement ultérieur.\n",
    "\n",
    "Après cela, nous préparons plusieurs structures de données qui nous aideront à transformer notre texte en entrées utilisables pour notre modèle LSTM :\n",
    "\n",
    "- `characters` : une liste de tous les caractères uniques dans notre texte, triés par ordre alphabétique. Cela servira à construire notre \"vocabulaire\" pour le modèle.\n",
    "- `char_to_index` et `index_to_char` : deux dictionnaires qui nous permettent de convertir entre des caractères et des indices numériques. Cela est nécessaire car notre modèle LSTM ne traite pas directement les caractères, mais les indices numériques qui les représentent.\n",
    "\n",
    "Nous définissons également deux hyperparamètres pour la préparation de nos données : `SEQ_LENGTH` et `STEP_SIZE`. `SEQ_LENGTH` détermine la longueur de chaque séquence d'entrée pour notre modèle, et `STEP_SIZE` détermine l'espacement entre ces séquences. En d'autres termes, pour chaque pas de `STEP_SIZE` caractères dans notre texte, nous préparons une séquence d'entrée de longueur `SEQ_LENGTH`.\n",
    "\n",
    "Ensuite, nous préparons nos entrées et nos cibles pour le modèle LSTM. Les entrées sont des séquences de `SEQ_LENGTH` caractères à partir de notre texte, et les cibles sont les caractères qui suivent directement ces séquences.\n",
    "\n",
    "Finalement, nous transformons ces séquences et cibles en représentations \"one-hot\". C'est une technique courante en apprentissage profond pour gérer les données catégorielles, comme nos caractères. Chaque caractère est représenté par un vecteur de la longueur de notre \"vocabulaire\", où toutes les positions sont zéro, sauf celle correspondant à ce caractère, qui est un. Ainsi, `x` et `y` sont des matrices tridimensionnelle et bidimensionnelle respectivement, où chaque ligne représente une séquence d'entrée ou une cible, et chaque colonne correspond à un caractère de notre \"vocabulaire\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fcad507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.layers import Activation, Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c562d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74afd9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filepath, 'rb') as file:\n",
    "    text = file.read().decode(encoding='utf-8').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a33097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8082f61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(set(text))\n",
    "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
    "index_to_char = dict((i, c) for i, c in enumerate(characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e48015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 200\n",
    "STEP_SIZE = 3\n",
    "\n",
    "sentences = []\n",
    "next_char = []\n",
    "\n",
    "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
    "    sentences.append(text[i: i + SEQ_LENGTH])\n",
    "    next_char.append(text[i + SEQ_LENGTH])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f82ab21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), SEQ_LENGTH, len(characters)), dtype=bool)\n",
    "y = np.zeros((len(sentences), len(characters)), dtype=bool)\n",
    "\n",
    "for i, satz in enumerate(sentences):\n",
    "    for t, char in enumerate(satz):\n",
    "        x[i, t, char_to_index[char]] = 1\n",
    "    y[i, char_to_index[next_char[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee39784",
   "metadata": {},
   "source": [
    "# Construction du modèle LSTM et génération de texte\n",
    "\n",
    "Dans ce bloc de code, nous commençons par construire notre modèle LSTM en utilisant l'API `Sequential` de Keras. Notre modèle comprend trois couches:\n",
    "\n",
    "1. Une couche LSTM avec 128 unités. C'est la couche qui fera la majeure partie du travail d'apprentissage des séquences de notre texte.\n",
    "2. Une couche `Dense` (c'est-à-dire une couche de neurones entièrement connectée) avec autant d'unités que nous avons de caractères uniques dans notre texte. Cette couche sert à convertir les sorties de notre couche LSTM en prédictions pour le prochain caractère à générer.\n",
    "3. Une couche `Activation` qui applique la fonction d'activation \"softmax\". Cette fonction convertit les scores de la couche Dense en probabilités pour chaque caractère possible.\n",
    "\n",
    "Après avoir défini l'architecture de notre modèle, nous le compilons avec la fonction de perte `categorical_crossentropy` (adaptée à notre problème de classification multiclasse) et l'optimiseur RMSprop. Ensuite, nous entraînons le modèle sur nos données d'entraînement préparées avec un `batch_size` de 256 pendant 4 `epochs`.\n",
    "\n",
    "Ensuite, nous définissons deux fonctions pour générer du texte à partir de notre modèle entraîné :\n",
    "\n",
    "1. `sample` : Cette fonction prend un tableau de prédictions de notre modèle (un score pour chaque caractère possible) et une \"température\", qui contrôle la diversité des textes générés. Un température plus élevée donne un texte plus aléatoire et diversifié, tandis qu'une température plus basse donne un texte plus prévisible. La fonction utilise ces scores pour générer une distribution de probabilité, puis tire un échantillon de cette distribution pour choisir le prochain caractère.\n",
    "\n",
    "2. `generate_text` : Cette fonction génère une séquence de texte de longueur donnée en utilisant notre modèle entraîné et la fonction `sample`. Elle commence par choisir aléatoirement une séquence de départ dans notre texte original, puis génère un caractère à la fois, en actualisant la séquence d'entrée à chaque pas.\n",
    "\n",
    "Finalement, nous générons et affichons une séquence de 20 caractères à partir de notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b7017fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(SEQ_LENGTH, len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fb68a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ftiag\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1453/1453 [==============================] - 46s 26ms/step - loss: 1.8373\n",
      "Epoch 2/4\n",
      "1453/1453 [==============================] - 37s 26ms/step - loss: 1.5341\n",
      "Epoch 3/4\n",
      "1453/1453 [==============================] - 38s 26ms/step - loss: 1.4665\n",
      "Epoch 4/4\n",
      "1453/1453 [==============================] - 39s 27ms/step - loss: 1.4316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a78f08dcd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=0.01))\n",
    "model.fit(x, y, batch_size=256, epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd881d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a6a9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(lenght, temperature):\n",
    "    # Initialise aléatoirement un numero d'index dans le text\n",
    "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
    "    # Initialise le texte predit\n",
    "    generated = ''\n",
    "    # Initialise la phrase selectionnée dans le texte\n",
    "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
    "    # Ajoute la phrase au texte de sortie\n",
    "    generated += sentence\n",
    "    # La boucle parcourt de 0 à \"lenght\" puis une autre boucle parcour la phrase pour initialisé \"x_predictions\",\n",
    "    # ensuite pour tout i on calcule les preds puis on utilise la fonction \"sample\" qui renvoie l'index du caractère\n",
    "    # à la fin on prends le caractère puis on l'ajoute à generated et enfin on actualise la phrase.\n",
    "    for i in range(lenght):\n",
    "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_predictions[0, t, char_to_index[char]] = 1\n",
    "        \n",
    "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
    "        next_index = sample(predictions, temperature)\n",
    "        next_character = index_to_char[next_index]\n",
    "        \n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "    \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2122f06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' thy friends are fled to wait upon thy foes, and crossly to thy good all fortune goes.  henry bolingbroke: bring forth these men. bushy and green, i will not vex your souls-- since presently your soul so the heart to the'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(20, 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
